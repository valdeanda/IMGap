{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure the pathway codes in the user provided file are formatted the same as it is throughout MetaGaia!!\n"
     ]
    }
   ],
   "source": [
    "print('Make sure the pathway codes in the user provided file are formatted the same as it is throughout MetaGaia!!')\n",
    "pathways_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in files\n",
    "user_df = pd.read_csv('../../../../nitrogen_KOs2.tsv', sep='\\t', index_col=False)\n",
    "pathway_df = pd.read_csv('../../../output/final_merged_database.tsv', sep='\\t', index_col=False)\n",
    "\n",
    "#Verify database name is valid\n",
    "databases_list = '[kegg, Cog, Pfam]'.upper().strip('[]').split(', ')\n",
    "for check in databases_list:\n",
    "    if check not in ['KEGG', 'COG', 'PFAM', 'EC_NUMBER']:\n",
    "        print('Invalid database name was entered!')\n",
    "        quit()\n",
    "    else:\n",
    "        #Convert to list\n",
    "        user_df[check] = user_df[check].str.split(', ')\n",
    "        index_cols = [col for col in user_df.columns if col != check]\n",
    "        user_df = (user_df.set_index(index_cols)[check].apply(pd.Series).stack().reset_index().drop('level_'+str(len(index_cols)), axis=1).rename(columns={0:check}))\n",
    "        for val in user_df[check]:\n",
    "            if check == 'KEGG':\n",
    "                if val[:3] != 'KO':\n",
    "                    user_df.loc[user_df[check] == val, check] = 'KO:' + val\n",
    "            elif check == 'PFAM':\n",
    "                if val[:4] != 'pfam':\n",
    "                    user_df.loc[user_df[check] == val, check] = 'pfam' + val[2:]\n",
    "            elif check == 'EC_NUMBER':\n",
    "                if val[:3] != 'EC':\n",
    "                    user_df.loc[user_df[check] == val, check] = 'EC:' + val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_df = pd.read_csv('../../../../nitrogen_KOs2.tsv', sep='\\t', index_col=False)\n",
    "# databases_list = '[kegg, Cog, Pfam]'.upper().strip('[]').split(', ')\n",
    "# user_df['COG'] = user_df['COG'].str.split(', ')\n",
    "# user_df = (user_df.set_index([col for col in user_df.columns if col != 'COG'])['COG'].apply(pd.Series).stack().reset_index().rename(columns={0:'COG'}))\n",
    "#user_df\n",
    "\n",
    "#user_df.loc[user_df['KEGG'] == 'K20932']['KEGG']\n",
    "\n",
    "#'K20932'[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to extract pathway information.\n"
     ]
    }
   ],
   "source": [
    "print('Beginning to extract pathway information.')\n",
    "for d in databases_list:\n",
    "    #Subset dataframe\n",
    "    extracted_df = pathway_df[pathway_df[d].isin(user_df[d])]\n",
    "    #If user provided file has multiple columns, map them to the extracted pathway dataframe\n",
    "    remove_cols = [col for col in databases_list if col != d]\n",
    "    extracted_df = extracted_df.drop(columns=remove_cols)\n",
    "    if len(user_df.drop(columns=databases_list).columns.tolist()) > 1:\n",
    "        extracted_df = extracted_df.merge(user_df.drop(columns=remove_cols), on=d, how='left')\n",
    "    #Rename datbase column so that concatenation can occur\n",
    "    cols_list = extracted_df.columns.tolist()\n",
    "    cols_list[cols_list.index(d)] = 'Database'\n",
    "    extracted_df.columns = cols_list\n",
    "    #Add dataframes to list\n",
    "    pathways_lst.append(extracted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished extracting information! File is saved in the \"output\" folder as \"extracted_pathways.tsv\".\n"
     ]
    }
   ],
   "source": [
    "#Combine all dataframes\n",
    "final_df = pd.concat(pathways_lst)\n",
    "final_df = final_df.set_index('Database')\n",
    "#Save file\n",
    "final_df.to_csv('../../../output/extracted_pathways.tsv', sep='\\t', index=True)\n",
    "print('Finished extracting information! File is saved in the \\\"output\\\" folder as \\\"extracted_pathways.tsv\\\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
